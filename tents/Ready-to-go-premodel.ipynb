{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "import imgaug as ia\n",
    "ia.seed(1)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from imgaug import augmenters as iaa \n",
    "from PIL import Image\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    folder path notation needs to be in string format. In jupyter, tab-autocomplete to avoid confusion. Examples: './example/',\n",
    "    '~/User/dsi/group_project/tent_satellite_imagery/tents/train/images'\n",
    "    \n",
    "    \"\"\"\n",
    "    #starting with a blank image list. We will then append that with each png file. \n",
    "    print(f'Building dataframe from {folder_path} contents.')\n",
    "   \n",
    "    images = []\n",
    "    for index, file in enumerate(glob.glob('./train/*.png')):\n",
    "        images.append(imageio.imread(file))\n",
    "\n",
    "    print(f'Library contains {len(images)} images')\n",
    "\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(f'{folder_path}*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            contents = (root.find('filename').text,\n",
    "                     int(root.find('size')[0].text),\n",
    "                     int(root.find('size')[1].text),\n",
    "                     member[0].text,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "            xml_list.append(contents)\n",
    "            \n",
    "    #lets user know how many images were processed\n",
    "    print(f'Processing {len(images)} .xml files') \n",
    "    \n",
    "#     sets up and df\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    \n",
    "#     this is the target feature, change as necessary\n",
    "    df['is_tent'] = (df['class']== 1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataframe from ./train/ contents.\n",
      "Library contains 2 images\n",
      "Processing 2 .xml files\n"
     ]
    }
   ],
   "source": [
    "df = process_folder('./train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = df[['xmin', 'ymin', 'xmax', 'ymax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df['class']\n",
    "filenames = df['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs = np.array(bboxes)\n",
    "encoder = LabelBinarizer()\n",
    "classes_onehot = encoder.fit_transform( classes )\n",
    "\n",
    "Y = np.concatenate( [ bboxes , classes_onehot ] , axis=1 )\n",
    "X = np.array( filenames )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
